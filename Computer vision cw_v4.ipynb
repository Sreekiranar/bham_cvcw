{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "### Loading matlab files in Python using Scipy\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('Brain.mat')\n",
    "T1, label = mat['T1'], mat['label']\n",
    "\n",
    "### T1 is the array with the input MRI images, 10 samples each of size 362x434 pixels.\n",
    "T1.shape\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(10):\n",
    "    img = T1[:,:,i]\n",
    "    ### standardising the float values between int of range(0-255)\n",
    "    img = ((img - img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "    images.append(img)\n",
    "    lab = label[:,:,i]\n",
    "    labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = images[5]\n",
    "label_image = labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2: Evaluating the performance\n",
    "# Before we move on to different approaches in obtaining the segmentation, \n",
    "#we will first define the evaluation metrics and get an accuracy measure with the groundtruth and verify the logics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelwise_IOU_label(input_image, ground_truth, label_class = 1):\n",
    "    mask1 = input_image == label_class\n",
    "    mask2 = ground_truth == label_class\n",
    "    iou_score = IOU_binary(mask1, mask2)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU_binary(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_binary(mask1, mask2):\n",
    "    mask1_pos = mask1.astype(np.float32)\n",
    "    mask2_pos = mask2.astype(np.float32)\n",
    "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_image(predict, label):\n",
    "    label_index = {0:'air',1:'skin',2:'skull',3:'csf',4:'gray matter',5:'white matter'}\n",
    "    scores = []\n",
    "    for pix_val, category in label_index.items():\n",
    "        predict_mask = (predict == pix_val)\n",
    "        label_mask = (label == pix_val)        \n",
    "        dice = dice_binary(predict_mask, label_mask)\n",
    "        scores.append(dice)\n",
    "    scores.append(sum(scores)/len(scores))\n",
    "    df = pd.DataFrame(columns=['air','skin','skull','csf','gray matter','white matter','0_mean'])\n",
    "    df.loc[0] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def score_images(predicts, labels):\n",
    "    df = pd.DataFrame(columns=['air','skin','skull','csf','gray matter','white matter','0_mean'])\n",
    "    for i, (predict, label) in enumerate(zip(predicts,labels)):\n",
    "        scores = score_image(predict,label)\n",
    "#         scores.append(sum(scores)/len(scores))\n",
    "        df = pd.concat([df, scores])\n",
    "#     print(\"Dice scores:\")\n",
    "#     for label in df.columns:\n",
    "#         print(f\"{label} : {df[label].mean()}\")\n",
    "    return df\n",
    "df = score_images(labels,labels)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1: MRI Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MRI Segementation - Approach 1 : K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air</th>\n",
       "      <th>skin</th>\n",
       "      <th>skull</th>\n",
       "      <th>csf</th>\n",
       "      <th>gray matter</th>\n",
       "      <th>white matter</th>\n",
       "      <th>0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.915257</td>\n",
       "      <td>0.249211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299259</td>\n",
       "      <td>0.820272</td>\n",
       "      <td>0.950255</td>\n",
       "      <td>0.539042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        air      skin  skull       csf  gray matter  white matter    0_mean\n",
       "0  0.915257  0.249211    0.0  0.299259     0.820272      0.950255  0.539042"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmeans_segmentation(input_image, no_of_classes = 6):\n",
    "    \n",
    "    h, w = input_image.shape\n",
    "    # reshape to 1D array\n",
    "    image_2d = input_image.reshape(h*w,1)\n",
    "\n",
    "    image_2d = np.float32(image_2d)\n",
    "    ### using cv2 kmeans\n",
    "    ### In criteria, we first set the algorithm termination criteria, either max no of iterations or desired result \n",
    "    ### here max iterations is set to 50, and the max score is 1.0\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 1.0)\n",
    "    K = no_of_classes\n",
    "    attempts = 100\n",
    "    ### calling kmeans\n",
    "    ret, label, center = cv2.kmeans(image_2d,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    result_image = res.reshape((input_image.shape))\n",
    "    \n",
    "    ### assigning each cluster to a label based on the range of pixels based on observation\n",
    "    out_image = np.zeros_like(result_image)\n",
    "    out_image = np.where(((result_image>45) & (result_image<55)), 1, out_image )\n",
    "    out_image = np.where(((result_image>75) & (result_image<95)), 3, out_image )\n",
    "    out_image = np.where(((result_image>115) & (result_image<135)), 4, out_image )\n",
    "    out_image = np.where(((result_image>145) & (result_image<160)), 5, out_image )\n",
    "    out_image = np.where(((result_image>200) & (result_image<210)), 2, out_image )\n",
    "    \n",
    "    return out_image\n",
    "\n",
    "out_image = kmeans_segmentation(input_image)\n",
    "score_image(out_image,label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MRI Segmentation - Approach 2 : Class by class Method: Filtering, Thresholding & Morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to filter labels with less than 10% area\n",
    "def filter_noise_label(out_label):\n",
    "    for i in np.unique(out_label):\n",
    "        if np.count_nonzero(out_label==i)<(0.1*out_label.shape[0]*out_label.shape[1]):\n",
    "            out_label = np.where(out_label==i,0,out_label)\n",
    "    return out_label\n",
    "### class wise segmentation\n",
    "def class_wise_segmentation(input_image, intermediate = False):\n",
    "    ### applying a 5x5 Gaussian blur to smoothen the image\n",
    "    blur_image = cv2.GaussianBlur(input_image.copy(),(5,5),cv2.BORDER_DEFAULT)\n",
    "    ### creating an empty image with the same shape as input_image\n",
    "    out_image = np.zeros_like(input_image)\n",
    "    ### air\n",
    "    ### thresholding with value of 17 for getting air\n",
    "    _, air = cv2.threshold(blur_image, 17 , 255, cv2.THRESH_BINARY)\n",
    "    ### applying a layer of closing and dilation\n",
    "    kernel = np.ones((5,5),dtype=np.uint8)\n",
    "    air_mask = ~cv2.morphologyEx(air, cv2.MORPH_CLOSE, kernel,iterations = 1)\n",
    "    air_mask = cv2.morphologyEx(air_mask, cv2.MORPH_DILATE, kernel, iterations =5)\n",
    "\n",
    "    ### skin\n",
    "    ### thresholding with a value of 50\n",
    "    th, skin = cv2.threshold(blur_image, 50, 255, cv2.THRESH_BINARY)\n",
    "    ### applying opening\n",
    "    kernel = np.ones((5,5),dtype=np.uint8)\n",
    "    dst2_open = cv2.morphologyEx(skin, cv2.MORPH_OPEN, kernel,iterations = 1)\n",
    "    \n",
    "    ### calling connected components function\n",
    "    retval, out_label, stats, centroids = cv2.connectedComponentsWithStats(dst2_open)\n",
    "    ### taking only skin\n",
    "    skin_mask = (out_label==1).astype(np.uint8)\n",
    "    ### applying dilation\n",
    "    kernel = np.ones((3,3),dtype=np.uint8)\n",
    "    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_DILATE, kernel,iterations = 1)\n",
    "    ### filtering noise labels from the connected components output\n",
    "    out_label = filter_noise_label(out_label)\n",
    "    ### masking the non_air parts by 6 to avoid being considered as air\n",
    "    out_image = np.where(air_mask!=0,0,6)\n",
    "    ### skin added with value 1 in the out image\n",
    "    out_image = np.where(skin_mask!=0,1,out_image)\n",
    "\n",
    "    ## skull\n",
    "    ### region inside skull is region which is disjoint with the union of the skin and the air mask\n",
    "    inside_skin = np.zeros_like(out_image)\n",
    "    inside_skin = np.where(out_image < 5,255,0)\n",
    "    ### applying dilation\n",
    "    kernel = np.ones((9,9),dtype=np.uint8)\n",
    "    inside_skin = cv2.morphologyEx(inside_skin.astype(np.uint8), cv2.MORPH_CLOSE, kernel,iterations = 1)\n",
    "    ### accessing the brain component with label 2\n",
    "    brain = np.where(out_label==2,255,0)\n",
    "    ### applying dilation\n",
    "    kernel = np.ones((7,7),dtype=np.uint8)\n",
    "    brain_filled = cv2.morphologyEx(brain.astype(np.uint8), cv2.MORPH_CLOSE, kernel,iterations = 5)\n",
    "    ### skull is the region between skin and brain\n",
    "    skull_mask = np.bitwise_xor(~inside_skin, brain_filled)\n",
    "    ### marking the pixels as skull with 2 in the out_image\n",
    "    out_image = np.where(skull_mask!=0,2,out_image)\n",
    "    \n",
    "    ### csf\n",
    "    ### thresholding with 100\n",
    "    _, csf = cv2.threshold(input_image, 100 , 255, cv2.THRESH_BINARY)\n",
    "    ### finding region inside skull which is disjoint to the union of the skin,air,and skull masks\n",
    "    inside_skull = np.zeros_like(out_image)\n",
    "    inside_skull = np.where(out_image<5, 255, 0).astype(np.uint8)\n",
    "    ### applying closing\n",
    "    kernel = np.ones((7,7),dtype=np.uint8)\n",
    "    inside_skull = cv2.morphologyEx(inside_skull, cv2.MORPH_CLOSE, kernel,iterations = 1)\n",
    "    ### filtering regions inside skull and the thresholded csf image\n",
    "    csf = np.bitwise_xor(csf,~inside_skull)\n",
    "    csf = np.where(out_image>5, csf, 0)\n",
    "    \n",
    "    ### finding the bounding box of the detected brain\n",
    "    retval, out_label_csf, stats, centroids = cv2.connectedComponentsWithStats(csf)\n",
    "    x, y, w, h, area = sorted(stats,key = lambda x:x[4],reverse = True)[1]\n",
    "    \n",
    "    ### from the images, we can see that the csf mask obtained need to retain its pixels in the borders\n",
    "    ### and need to erode the parts inside which is identified as csf\n",
    "    ### we will use a selective erosion by masking\n",
    "    \n",
    "    # Supervised Eliptical Erosion \n",
    "    \n",
    "    ellipse_mask = np.zeros_like(csf)\n",
    "    ### finding a large ellipse inside the brain to erode\n",
    "    cv2.ellipse(ellipse_mask, ((int((x+w+x)/2),int((y+y+h)/2)), (0.95*w,0.95*h), 0.0), (255, 255, 255), -1);\n",
    "    ### making a mask of the ellipse and copying the contents of csf inside the mask\n",
    "    csf_centre_thin = np.where(ellipse_mask & csf!=0, csf, 0)\n",
    "    ### taking the rest of the region outside the ellipse\n",
    "    csf_rest = np.where(ellipse_mask & csf==0, csf,0)\n",
    "    ### eroding the content inside the ellipse\n",
    "    kernel = np.ones((3,3),dtype=np.uint8)\n",
    "    csf_centre_thin = cv2.morphologyEx(csf_centre_thin, cv2.MORPH_ERODE, kernel,iterations = 1)\n",
    "    ### merging the newly eroded content inside the ellipse and the original content outside ellipse\n",
    "    csf = csf_rest + csf_centre_thin \n",
    "    \n",
    "    out_image = np.where(csf!=0, 3, out_image)\n",
    "    \n",
    "    ### gray & white matter\n",
    "    ### gray matter is directly obtained from thresholding at 140 and removing the non_brain regions\n",
    "    _, gray_matter = cv2.threshold(blur_image, 140 , 255, cv2.THRESH_BINARY)\n",
    "    gray_matter = np.where(~inside_skull>0, gray_matter,0)\n",
    "    out_image = np.where(gray_matter!=0, 5, out_image)\n",
    "    ### rest of the regions which does not belong to any category is the white matter\n",
    "    out_image = np.where(out_image>5, 4, out_image)\n",
    "    return [out_image,inside_skull, air_mask, inside_skin, skin_mask, skull_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Approach 3: Combining Kmeans and Class_by_Class_segmentation results\n",
    "def combined_kmeans_and_class_by_class(input_image, masks, kmeans_out_image):\n",
    "    ### accesing the intermediate outputs from class_by_class segmentation\n",
    "    out_image,inside_skull, air_mask, inside_skin, skin_mask, skull_mask = masks\n",
    "    ### creating new output image, masks for new gray and white matter\n",
    "    new_image = np.zeros_like(out_image)\n",
    "    combined_gray_matter = np.zeros_like(out_image)\n",
    "    combined_white_matter = np.zeros_like(out_image)\n",
    "\n",
    "    ### taking gray matter from kmeans after filtering the non_brain regions\n",
    "    gray_matter_kmeans = (kmeans_out_image==4)\n",
    "    combined_gray_matter = np.where(~inside_skull!=0, gray_matter_kmeans, combined_gray_matter)\n",
    "    ### taking white matter from kmeans after filtering the non_brain regions\n",
    "    white_matter_kmeans = (kmeans_out_image==5)\n",
    "    combined_white_matter = np.where(~inside_skull!=0, white_matter_kmeans, new_image)\n",
    "    ### labeling gray and white matter\n",
    "    new_image = np.where(combined_gray_matter!=0, 4, new_image)\n",
    "    new_image = np.where(combined_white_matter!=0, 5, new_image)\n",
    "\n",
    "    ### improving skull mask from kmeans\n",
    "    air_kmeans = (kmeans_out_image==0)\n",
    "    ### taking the thresholded air_mask\n",
    "    new_skull_mask= np.bitwise_or(air_kmeans,air_mask)\n",
    "    new_skull_mask = np.bitwise_and(new_skull_mask,~inside_skin)\n",
    "    ### applying dilation\n",
    "    kernel = np.ones((3,3),dtype=np.uint8)\n",
    "    new_skull_mask = cv2.morphologyEx(new_skull_mask, cv2.MORPH_DILATE, kernel,iterations = 1)\n",
    "    ### now the skull obtained from supervised approach had no gaps, the gaps are actually part of skin\n",
    "    skin_gaps = skull_mask - new_skull_mask*255\n",
    "    ### adding the skin gaps to the detected skin from approach 2\n",
    "    skin_gaps = np.where(skin_gaps>0, 1,0)\n",
    "    new_skin_mask = skin_mask | skin_gaps\n",
    "    ### adding labels to the out image\n",
    "    new_image = np.where(air_mask!=0,0,new_image)\n",
    "    new_image = np.where(new_skin_mask!=0, 1, new_image)\n",
    "    new_image = np.where(new_skull_mask!=0, 2, new_image)\n",
    "    new_image = np.where(out_image==3, 3, new_image)\n",
    "    new_image = np.where(((~inside_skin!=0)&(new_image==0)), 4, out_image)\n",
    "    new_image = np.where(combined_white_matter!=0, 5, new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0_mean</th>\n",
       "      <th>air</th>\n",
       "      <th>csf</th>\n",
       "      <th>gray matter</th>\n",
       "      <th>skin</th>\n",
       "      <th>skull</th>\n",
       "      <th>white matter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_by_class</th>\n",
       "      <td>0.894869</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.906819</td>\n",
       "      <td>0.914524</td>\n",
       "      <td>0.821126</td>\n",
       "      <td>0.924378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <td>0.913848</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.816944</td>\n",
       "      <td>0.952760</td>\n",
       "      <td>0.914524</td>\n",
       "      <td>0.821126</td>\n",
       "      <td>0.992313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>0.536812</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>0.291857</td>\n",
       "      <td>0.819505</td>\n",
       "      <td>0.243762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label             0_mean       air       csf  gray matter      skin     skull  \\\n",
       "method                                                                          \n",
       "class_by_class  0.894869  0.985423  0.816944     0.906819  0.914524  0.821126   \n",
       "combined        0.913848  0.985423  0.816944     0.952760  0.914524  0.821126   \n",
       "kmeans          0.536812  0.915233  0.291857     0.819505  0.243762  0.000000   \n",
       "\n",
       "label           white matter  \n",
       "method                        \n",
       "class_by_class      0.924378  \n",
       "combined            0.992313  \n",
       "kmeans              0.950517  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scoring for all 10 images\n",
    "predicts_class_by_class = []\n",
    "predicts_kmeans = []\n",
    "predicts_combined = []\n",
    "for i, image in enumerate(images):\n",
    "    masks = class_wise_segmentation(image)\n",
    "    kmeans_out = kmeans_segmentation(image)\n",
    "    combined_out = combined_kmeans_and_class_by_class(image, masks, kmeans_out)\n",
    "    predicts_class_by_class.append(masks[0])\n",
    "    predicts_kmeans.append(kmeans_out)\n",
    "    predicts_combined.append(combined_out)\n",
    "\n",
    "df_class_by_class = score_images(predicts_class_by_class,labels)\n",
    "df_kmeans = score_images(predicts_kmeans,labels)\n",
    "df_combined = score_images(predicts_combined,labels)\n",
    "df_1 = df_class_by_class.mean(axis=0).reset_index(name = 'score')\n",
    "df_1['method'] = 'class_by_class'\n",
    "df_2 = df_kmeans.mean(axis=0).reset_index(name = 'score')\n",
    "df_2['method'] = 'kmeans'\n",
    "df_3 = df_combined.mean(axis=0).reset_index(name = 'score')\n",
    "df_3['method'] = 'combined'\n",
    "df = pd.concat([df_1,df_2,df_3],axis=0)\n",
    "df.rename(columns = {'index':'label'},inplace=True)\n",
    "# print(df)\n",
    "out = pd.pivot_table(df,values='score',index='method',columns='label')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D segmentation\n",
    "### Approach 1: Kmeans 3D\n",
    "def kmeans3d_segmentation(input_image):\n",
    "#     input_image = np.asarray(images).reshape((362,434,10))\n",
    "    h, w, c = input_image.shape\n",
    "    ### same as 2d, but adding 10 channels\n",
    "    # reshape to 1D array of 10 channels\n",
    "    image_3d = input_image.reshape(h*w,c)\n",
    "\n",
    "    image_3d = np.float32(image_3d)\n",
    "\n",
    "    ### using cv2 kmeans\n",
    "    ### In criteria, we first set the algorithm termination criteria, either max no of iterations or desired result \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 6\n",
    "    attempts = 10\n",
    "    ret,label,center = cv2.kmeans(image_3d,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    result_image = res.reshape((input_image.shape))\n",
    "    ### assigning each cluster to a label based on the range of pixels\n",
    "    out_image = np.zeros_like(result_image)\n",
    "    out_image = np.where(((result_image>45) & (result_image<55)), 1, out_image )\n",
    "    out_image = np.where(((result_image>75) & (result_image<95)), 3, out_image )\n",
    "    out_image = np.where(((result_image>115) & (result_image<135)), 4, out_image )\n",
    "    out_image = np.where(((result_image>145) & (result_image<160)), 5, out_image )\n",
    "    out_image = np.where(((result_image>200) & (result_image<210)), 2, out_image )\n",
    "    \n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air</td>\n",
       "      <td>0.551430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skin</td>\n",
       "      <td>0.118988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skull</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csf</td>\n",
       "      <td>0.144117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray matter</td>\n",
       "      <td>0.426448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white matter</td>\n",
       "      <td>0.382965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_mean</td>\n",
       "      <td>0.270658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label     score\n",
       "0           air  0.551430\n",
       "1          skin  0.118988\n",
       "2         skull  0.000000\n",
       "3           csf  0.144117\n",
       "4   gray matter  0.426448\n",
       "5  white matter  0.382965\n",
       "6        0_mean  0.270658"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = kmeans3d_segmentation(images)\n",
    "df = score_images(predicts, labels)\n",
    "df_kmeans3 = df.mean(axis=0).reset_index()\n",
    "df_kmeans3.rename(columns={'index':'label',0:'score'},inplace=True)\n",
    "df_kmeans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grayscaling to a single image and processing\n",
    "# Considering the 10 images are in 3d, we are converting the image to a \n",
    "# grayscale image by averaging all channels, and processing through the 2d \n",
    "# segmentation algorithm. The ground truth will be taken with the pixel_by_pixel mode value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores using combined kmeans + class_by_class method: \n",
      "\n",
      "        air      skin     skull       csf  gray matter  white matter    0_mean\n",
      "0  0.986245  0.912427  0.822814  0.771098     0.901995      0.887595  0.880362\n"
     ]
    }
   ],
   "source": [
    "### taking mean of the 10 images to get the single channel image \n",
    "images = np.asarray(images)\n",
    "gray_scale = np.mean(images,axis=0).astype(np.uint8)\n",
    "### taking the mode across the 10 images for each pixel to arrive at a single label image\n",
    "mode_label = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=labels)\n",
    "### calling three algorithms\n",
    "masks = class_wise_segmentation(gray_scale)\n",
    "kmeans_out = kmeans_segmentation(gray_scale)\n",
    "combined_out = combined_kmeans_and_class_by_class(gray_scale, masks, kmeans_out)\n",
    "\n",
    "print('Dice scores using combined kmeans + class_by_class method: \\n')\n",
    "out = score_image(combined_out,mode_label)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air</th>\n",
       "      <th>skin</th>\n",
       "      <th>skull</th>\n",
       "      <th>csf</th>\n",
       "      <th>gray matter</th>\n",
       "      <th>white matter</th>\n",
       "      <th>0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986245</td>\n",
       "      <td>0.912427</td>\n",
       "      <td>0.822814</td>\n",
       "      <td>0.771098</td>\n",
       "      <td>0.901995</td>\n",
       "      <td>0.887595</td>\n",
       "      <td>0.880362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        air      skin     skull       csf  gray matter  white matter    0_mean\n",
       "0  0.986245  0.912427  0.822814  0.771098     0.901995      0.887595  0.880362"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Channel by Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## third approach is essentially processing each channel through the 2d segemntation and combining the results\n",
    "images = np.asarray(images)\n",
    "outs = np.zeros_like(images)\n",
    "for i,image in enumerate(images):\n",
    "    masks = class_wise_segmentation(image)\n",
    "    outs[i,:,:] = masks[0]\n",
    "### calculating the dice will be essentially calculating the dice of each channel and averaging\n",
    "df = score_images(outs, labels)\n",
    "### which gives the same result as 2d segmentation as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
